{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 59093,
          "databundleVersionId": 7469972,
          "sourceType": "competition"
        },
        {
          "sourceId": 7392733,
          "sourceType": "datasetVersion",
          "datasetId": 4297749
        },
        {
          "sourceId": 7392775,
          "sourceType": "datasetVersion",
          "datasetId": 4297782
        },
        {
          "sourceId": 7402356,
          "sourceType": "datasetVersion",
          "datasetId": 4304475
        },
        {
          "sourceId": 7487364,
          "sourceType": "datasetVersion",
          "datasetId": 4359072
        },
        {
          "sourceId": 7820246,
          "sourceType": "datasetVersion",
          "datasetId": 4581818
        },
        {
          "sourceId": 7821030,
          "sourceType": "datasetVersion",
          "datasetId": 4582325
        },
        {
          "sourceId": 158958765,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 164443259,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 165361980,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 166552735,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 30646,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "HMS - EfficientNetB0[Two-Stage]",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SEOYUNJE/github.io/blob/main/HMS_EfficientNetB0%5BTwo_Stage%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "QanyxNzk2pK3",
        "outputId": "da11988e-cb28-439a-c7d2-9e6fa1862d95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f284621a-f027-43a1-8c1c-46ee24d87c33\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f284621a-f027-43a1-8c1c-46ee24d87c33\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"seoyunje\",\"key\":\"89b84956e32443034cc20e45766929a8\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -1ha kaggle.json"
      ],
      "metadata": {
        "id": "mFRv4Uc-2yGT",
        "outputId": "69f7063e-2b02-4fd9-9a14-e8b9f3b3b5cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "D9ffpznn3WST"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d cdeotte/brain-spectrograms"
      ],
      "metadata": {
        "id": "lkWJyNct33D7",
        "outputId": "d874cb3a-dc8a-43d1-f559-1e51383c95bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading brain-spectrograms.zip to /content\n",
            "100% 2.66G/2.66G [02:18<00:00, 18.9MB/s]\n",
            "100% 2.66G/2.66G [02:18<00:00, 20.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip brain-spectrograms.zip"
      ],
      "metadata": {
        "id": "Klqlec-Z4PGE",
        "outputId": "ea2ecb1b-a7cf-4621-b9cf-2630feb2de6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  brain-spectrograms.zip\n",
            "  inflating: specs.npy               \n",
            "  inflating: train.pqt               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d cdeotte/kaggle-kl-div"
      ],
      "metadata": {
        "id": "Sv8ykqKg5Klx",
        "outputId": "4ed26477-03b1-4326-fb0d-358cff5a5a09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading kaggle-kl-div.zip to /content\n",
            "\r  0% 0.00/2.95k [00:00<?, ?B/s]\n",
            "\r100% 2.95k/2.95k [00:00<00:00, 1.54MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip kaggle-kl-div"
      ],
      "metadata": {
        "id": "ThGCU0Qm5NMu",
        "outputId": "1c02e5e2-2163-4828-dfe0-9fa47b4081f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  kaggle-kl-div.zip\n",
            "  inflating: kaggle_kl_div.py        \n",
            "  inflating: kaggle_metric_utilities.py  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d seoyunje/labelinglow-quality"
      ],
      "metadata": {
        "id": "sy2bBQst5X7W",
        "outputId": "39f02599-ef37-4f37-e6fe-91020a878ad8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading labelinglow-quality.zip to /content\n",
            "100% 387k/387k [00:00<00:00, 573kB/s]\n",
            "100% 387k/387k [00:00<00:00, 573kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip labelinglow-quality"
      ],
      "metadata": {
        "id": "hgzGt97m5fst",
        "outputId": "d70bafe2-4414-43f3-c1b1-315b2301ea94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  labelinglow-quality.zip\n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d seoyunje/low-quality"
      ],
      "metadata": {
        "id": "iBwu4ix95iMx",
        "outputId": "3d7cfccb-d48f-4915-a181-ecc10485821f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading low-quality.zip to /content\n",
            " 99% 71.0M/72.1M [00:05<00:00, 19.7MB/s]\n",
            "100% 72.1M/72.1M [00:05<00:00, 12.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip low-quality"
      ],
      "metadata": {
        "id": "uHkS2fOc5ogg",
        "outputId": "2b7cb943-42f4-4809-a79d-3351f4dc38ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  low-quality.zip\n",
            "  inflating: EffNet_v1_f0_low.h5     \n",
            "  inflating: EffNet_v1_f1_low.h5     \n",
            "  inflating: EffNet_v1_f2_low.h5     \n",
            "  inflating: EffNet_v1_f3_low.h5     \n",
            "  inflating: EffNet_v1_f4_low.h5     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d cdeotte/tf-efficientnet-imagenet-weights"
      ],
      "metadata": {
        "id": "gbONUdkU5sZc",
        "outputId": "253395b5-1fe2-4352-8d71-4777ef740e81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading tf-efficientnet-imagenet-weights.zip to /content\n",
            "100% 265M/266M [00:13<00:00, 21.9MB/s]\n",
            "100% 266M/266M [00:13<00:00, 20.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip tf-efficientnet-imagenet-weights"
      ],
      "metadata": {
        "id": "eFRVIHz05xty",
        "outputId": "ec30650f-7165-4876-e208-8e85e93c997e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  tf-efficientnet-imagenet-weights.zip\n",
            "  inflating: efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5  \n",
            "  inflating: efficientnet-b1_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5  \n",
            "  inflating: efficientnet-b2_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5  \n",
            "  inflating: efficientnet-b3_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5  \n",
            "  inflating: efficientnet-b4_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5  \n",
            "  inflating: efficientnet-b5_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d seanbearden/tf-efficientnet-noisy-student-weights"
      ],
      "metadata": {
        "id": "0tm05l1A53ex",
        "outputId": "06ea5bc1-9ce5-4b10-92c1-10fa989aa7bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading tf-efficientnet-noisy-student-weights.zip to /content\n",
            "100% 635M/637M [00:33<00:00, 21.1MB/s]\n",
            "100% 637M/637M [00:33<00:00, 20.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip tf-efficientnet-noisy-student-weights"
      ],
      "metadata": {
        "id": "n1h7Vq7a6ACO",
        "outputId": "7b75fe03-8260-4f43-fe58-7dbe54d8a999",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  tf-efficientnet-noisy-student-weights.zip\n",
            "  inflating: efficientnet-b0_noisy-student_notop.h5  \n",
            "  inflating: efficientnet-b1_noisy-student_notop.h5  \n",
            "  inflating: efficientnet-b2_noisy-student_notop.h5  \n",
            "  inflating: efficientnet-b3_noisy-student_notop.h5  \n",
            "  inflating: efficientnet-b4_noisy-student_notop.h5  \n",
            "  inflating: efficientnet-b5_noisy-student_notop.h5  \n",
            "  inflating: efficientnet-b6_noisy-student_notop.h5  \n",
            "  inflating: efficientnet-b7_noisy-student_notop.h5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c hms-harmful-brain-activity-classification"
      ],
      "metadata": {
        "id": "al3YmYeN6CkG",
        "outputId": "52145097-6bb9-4458-e6a4-565a151b3e00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading hms-harmful-brain-activity-classification.zip to /content\n",
            "100% 18.4G/18.4G [14:51<00:00, 23.1MB/s]\n",
            "100% 18.4G/18.4G [14:51<00:00, 22.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d seoyunje/albumentation-1-4-1"
      ],
      "metadata": {
        "id": "3y__IEhv_HeH",
        "outputId": "75f6bde1-757c-4d3e-864a-3e088c7be4d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading albumentation-1-4-1.zip to /content\n",
            "100% 192M/192M [00:10<00:00, 23.6MB/s]\n",
            "100% 192M/192M [00:10<00:00, 18.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip albumentation-1-4-1"
      ],
      "metadata": {
        "id": "Zenjzozt_KYq",
        "outputId": "664a2842-fa52-41d7-b650-30358d617513",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  albumentation-1-4-1.zip\n",
            "  inflating: PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl  \n",
            "  inflating: albumentations-1.4.0-py3-none-any.whl  \n",
            "  inflating: imageio-2.34.0-py3-none-any.whl  \n",
            "  inflating: joblib-1.3.2-py3-none-any.whl  \n",
            "  inflating: lazy_loader-0.3-py3-none-any.whl  \n",
            "  inflating: networkx-3.2.1-py3-none-any.whl  \n",
            "  inflating: numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl  \n",
            "  inflating: opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl  \n",
            "  inflating: opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl  \n",
            "  inflating: packaging-23.2-py3-none-any.whl  \n",
            "  inflating: pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl  \n",
            "  inflating: qudida-0.0.4-py3-none-any.whl  \n",
            "  inflating: scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl  \n",
            "  inflating: scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl  \n",
            "  inflating: scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl  \n",
            "  inflating: threadpoolctl-3.3.0-py3-none-any.whl  \n",
            "  inflating: tifffile-2024.2.12-py3-none-any.whl  \n",
            "  inflating: typing_extensions-4.10.0-py3-none-any.whl  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d seoyunje/efficientnet-whl"
      ],
      "metadata": {
        "id": "DXKnkY8X_OSP",
        "outputId": "00aa815c-04d1-4a71-ab9e-c7dc9ea15224",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading efficientnet-whl.zip to /content\n",
            " 98% 75.0M/76.4M [00:05<00:00, 23.7MB/s]\n",
            "100% 76.4M/76.4M [00:05<00:00, 15.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip efficientnet-whl"
      ],
      "metadata": {
        "id": "hg0oeVNw_YoK",
        "outputId": "9b8bb34b-c5c5-4d48-e238-65abd23ec1f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  efficientnet-whl.zip\n",
            "replace Keras_Applications-1.0.8-py3-none-any.whl? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d seoyunje/denosing-with-dmey"
      ],
      "metadata": {
        "id": "_WFj8ZSO_fdu",
        "outputId": "675edef9-b376-4b6f-f36b-a6ec9df1015c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "404 - Not Found - No gcs url found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip denosing-with-dmey"
      ],
      "metadata": {
        "id": "yt9qqWID_g4j",
        "outputId": "4c159ef1-401c-4563-9a9b-0a72dfcb9e9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open denosing-with-dmey, denosing-with-dmey.zip or denosing-with-dmey.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d seoyunje/bandpass"
      ],
      "metadata": {
        "id": "tbNo1ZVl_8RV",
        "outputId": "62e80cf2-ee60-457d-88c5-b9afcf12694a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "404 - Not Found - No gcs url found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip bandpass"
      ],
      "metadata": {
        "id": "aeMKys4c_9RJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"padding: 25px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#A51C30\"><b><span style='color:#FFFFFF'>1 |</span></b> <b>INTRODUCTION</b></div>"
      ],
      "metadata": {
        "id": "IgDQoa672P_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#A51C30'> 1.1 </span> Initializing Accelerator</b>"
      ],
      "metadata": {
        "id": "Q6Kk3M3g2P_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''I'm gonna use GPU'''\n",
        "\n",
        "# GPU T4x2: For AI & DeepLearning\n",
        "# GPU P100: For High Performacne Computing(HPC)\n",
        "\n",
        "'''We're gonna build AI model'''\n",
        "\n",
        "# cleaning memory\n",
        "import gc\n",
        "import ctypes\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "# CUDA: 일종의 GPU 병렬 프로그래밍\n",
        "# CUDA GPU 2개를 지정\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
        "import tensorflow as tf\n",
        "print(f'tensorflow version', tf.__version__)\n",
        "\n",
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# USE Multiple GPU\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if len(gpus) <=1:\n",
        "    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
        "    print(f'Using {len(gpus)} GPUS')\n",
        "else:\n",
        "    strategy = tf.distribute.MirroredStrategy()\n",
        "    print(f'Using {len(gpus)} GPUS')\n",
        "\n",
        "VER = 1 # Starter Version\n",
        "\n",
        "LOAD_MODELS_FROM = '/kaggle/input/low-quality/'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T11:29:38.356028Z",
          "iopub.execute_input": "2024-03-12T11:29:38.356392Z",
          "iopub.status.idle": "2024-03-12T11:29:56.138201Z",
          "shell.execute_reply.started": "2024-03-12T11:29:38.356362Z",
          "shell.execute_reply": "2024-03-12T11:29:56.13697Z"
        },
        "trusted": true,
        "id": "0-qFNCmv2P_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install /kaggle/input/wheel-albumentation/albumentations-1.4.0-py3-none-any.whl"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T11:29:56.141246Z",
          "iopub.execute_input": "2024-03-12T11:29:56.142056Z",
          "iopub.status.idle": "2024-03-12T11:30:31.337036Z",
          "shell.execute_reply.started": "2024-03-12T11:29:56.142013Z",
          "shell.execute_reply": "2024-03-12T11:30:31.335392Z"
        },
        "trusted": true,
        "id": "YrCfDL452P_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### USE MIXED PRECISION\n",
        "- Not using: Full Precision\n",
        "- Using: Mixed Precision\n",
        "\n",
        "- `사용이유`: 계산을 보다 더 효율적으로 수행하기 위해서"
      ],
      "metadata": {
        "id": "1rgoxznF2P_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MIX = True\n",
        "if MIX:\n",
        "    tf.config.optimizer.set_experimental_options({'auto_mixed_precision':True})\n",
        "    print('Mixed Precision enabled')\n",
        "else:\n",
        "    print('Using full precision')"
      ],
      "metadata": {
        "trusted": true,
        "id": "Z3hMomNJ2P_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clean Memory"
      ],
      "metadata": {
        "id": "SYlda2ZE2P_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_memory():\n",
        "    # malloc_trim: 현재 사용되지 않는 메모리를 시스템에서 다시 반환함0\n",
        "    ctypes.CDLL('libc.so.6').malloc_trim(0)\n",
        "    gc.collect()\n",
        "clean_memory()"
      ],
      "metadata": {
        "trusted": true,
        "id": "8c5dTshW2P_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"padding: 25px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#A51C30\"><b><span style='color:#FFFFFF'>2 |</span></b> <b>Load and Read Data</b></div>"
      ],
      "metadata": {
        "id": "1wERYOAG2P_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/train.csv\")\n",
        "TARGETS = df.columns[-6:] # series 형태로 반환됨\n",
        "print('train shape', df.shape)\n",
        "print('targets', list(TARGETS)) #list로 바꿈\n",
        "display(df.head())"
      ],
      "metadata": {
        "trusted": true,
        "id": "_9C-lmE22P_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#A51C30'> 2.1 </span> Non Overlapping EED ID Train Data</b>"
      ],
      "metadata": {
        "id": "D77uqxT32P_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = df.groupby('eeg_id')[['spectrogram_id','spectrogram_label_offset_seconds']].agg(\n",
        "    {'spectrogram_id':'first','spectrogram_label_offset_seconds':'min'})\n",
        "train.columns = ['spec_id','min']\n",
        "\n",
        "tmp = df.groupby('eeg_id')[['spectrogram_id','spectrogram_label_offset_seconds']].agg(\n",
        "    {'spectrogram_label_offset_seconds':'max'})\n",
        "train['max'] = tmp\n",
        "\n",
        "tmp = df.groupby('eeg_id')[['patient_id']].agg('first')\n",
        "train['patient_id'] = tmp\n",
        "\n",
        "tmp = df.groupby('eeg_id')[TARGETS].agg('sum')\n",
        "for t in TARGETS:\n",
        "    train[t] = tmp[t].values\n",
        "\n",
        "y_data = train[TARGETS].values\n",
        "y_data = y_data / y_data.sum(axis=1,keepdims=True)\n",
        "train[TARGETS] = y_data\n",
        "\n",
        "df['total_evaluators'] = df[['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']].sum(axis=1)\n",
        "tmp = df.groupby('eeg_id')['total_evaluators'].agg('first')\n",
        "train['total_evaluators'] = tmp\n",
        "\n",
        "tmp = df.groupby('eeg_id')[['expert_consensus']].agg('first')\n",
        "train['target'] = tmp\n",
        "\n",
        "train = train.reset_index()\n",
        "print('Train non-overlapp eeg_id shape:', train.shape )\n",
        "train.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "VadsYb9N2P_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.histplot(data=train, x='total_evaluators', bins='auto')\n",
        "plt.xlabel('total_evaluators')\n",
        "plt.ylabel('count')\n",
        "plt.title('Distribution of total evaluators')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "rKuAxvdm2P_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#A51C30'> 2.2 </span> Read Train Spectrogrmas </b>"
      ],
      "metadata": {
        "id": "5y8NiSVb2P_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "PATH = '/kaggle/input/hms-harmful-brain-activity-classification/train_spectrograms/'\n",
        "files = os.listdir(PATH)\n",
        "print(f'there are {len(files)} spectrograms parquets')\n",
        "\n",
        "# Numpy Loading\n",
        "spectrograms = np.load('/kaggle/input/brain-spectrograms/specs.npy',allow_pickle=True).item()"
      ],
      "metadata": {
        "trusted": true,
        "id": "qXxI9fnC2P_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#A51C30'> 2.3 </span> Read EEG Spectrogrmas </b>"
      ],
      "metadata": {
        "id": "PBIIXZxz2P_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NAMES = ['LL','LP','RP','RR']\n",
        "\n",
        "FEATS = [['Fp1','F7','T3','T5','O1'],\n",
        "         ['Fp1','F3','C3','P3','O1'],\n",
        "         ['Fp2','F8','T4','T6','O2'],\n",
        "         ['Fp2','F4','C4','P4','O2']]"
      ],
      "metadata": {
        "trusted": true,
        "id": "MbEJoT962P_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage import gaussian_filter\n",
        "from scipy.signal import butter, lfilter, iirnotch\n",
        "\n",
        "def total_filter(data, sampling_rate=200, order=3):\n",
        "    # Normalization\n",
        "    nyquist = 0.5 * sampling_rate\n",
        "    # First Filtering: Notch Filtering[특정 주파수 제거]\n",
        "    notch_freq = 60\n",
        "    Q = 30\n",
        "    notch_coefficients = iirnotch(w0=notch_freq / nyquist, Q=Q)\n",
        "\n",
        "    filtered_data = lfilter(notch_coefficients[0], notch_coefficients[1], data, axis=0)\n",
        "    # Second Filtering: Band Pass Filtering[특정 주파수 강조]\n",
        "    # 강조할 주파수 대역: 0.5~20Hz\n",
        "    normal_lowest_cutoff = 0.5/nyquist\n",
        "    normal_highest_cutoff = 25/nyquist\n",
        "    b, a = butter(order, [normal_lowest_cutoff, normal_highest_cutoff], btype='band', analog=False)\n",
        "\n",
        "    filtered_data = lfilter(b, a , filtered_data, axis=0)\n",
        "\n",
        "    # Third Filtering: Guassian Pass[Image Smoothing]\n",
        "    # Small Sigma: 저주파수 성분 보존, 고주파 잡음을 감소\n",
        "    # Big Sigma: 더 작은 지역적인 특징\n",
        "    filtered_data = gaussian_filter(filtered_data, sigma=1, order=5, mode='reflect')\n",
        "    return filtered_data"
      ],
      "metadata": {
        "trusted": true,
        "id": "t8wIGBTc2P_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "\n",
        "def spectrogram_from_eeg(parquet_path, display=False):\n",
        "\n",
        "    # LOAD MIDDLE 50 SECONDS OF EEG SERIES\n",
        "    eeg = pd.read_parquet(parquet_path)\n",
        "    middle = (len(eeg)-10_000)//2\n",
        "    eeg = eeg.iloc[middle:middle+10_000]\n",
        "\n",
        "    # VARIABLE TO HOLD SPECTROGRAM\n",
        "    img = np.zeros((128,256,4),dtype='float32')\n",
        "\n",
        "    if display: plt.figure(figsize=(10,7))\n",
        "    signals = []\n",
        "    for k in range(4):\n",
        "        COLS = FEATS[k]\n",
        "        if k < 4:\n",
        "            for kk in range(4):\n",
        "\n",
        "                # COMPUTE PAIR DIFFERENCES\n",
        "                x = eeg[COLS[kk]].values - eeg[COLS[kk+1]].values\n",
        "\n",
        "                # FILL NANS\n",
        "                m = np.nanmean(x)\n",
        "                if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n",
        "                else: x[:] = 0\n",
        "\n",
        "                total_filter(x)\n",
        "\n",
        "                signals.append(x)\n",
        "\n",
        "                # RAW SPECTROGRAM\n",
        "                mel_spec = librosa.feature.melspectrogram(y=x, sr=200, hop_length=len(x)//256,\n",
        "                     n_fft=1024, n_mels=128, fmin=0, fmax=20, win_length=128)\n",
        "\n",
        "                # LOG TRANSFORM\n",
        "                width = (mel_spec.shape[1]//32)*32\n",
        "                mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[:,:width]\n",
        "\n",
        "                # STANDARDIZE TO -1 TO 1\n",
        "                mel_spec_db = (mel_spec_db+40)/40\n",
        "                img[:,:,k] += mel_spec_db\n",
        "\n",
        "        # AVERAGE THE 4 MONTAGE DIFFERENCES\n",
        "            img[:,:,k] /= 4.0\n",
        "\n",
        "\n",
        "\n",
        "        if display:\n",
        "            plt.subplot(3,2,k+1)\n",
        "            plt.imshow(img[:,:,k],aspect='auto',origin='lower')\n",
        "            plt.title(f'EEG {eeg_id} - Spectrogram {NAMES[k]}')\n",
        "\n",
        "    if display:\n",
        "        plt.show()\n",
        "        plt.figure(figsize=(10,5))\n",
        "        offset = 0\n",
        "        for k in range(4):\n",
        "            if k>0: offset -= signals[3-k].min()\n",
        "            plt.plot(range(10000),signals[k]+offset,label=NAMES[3-k])\n",
        "            offset += signals[3-k].max()\n",
        "        plt.legend()\n",
        "        plt.title(f'EEG {eeg_id} Signals')\n",
        "        plt.show()\n",
        "        print(); print('#'*25); print()\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "trusted": true,
        "id": "kg9x22Na2P_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EEG Spectrograms 50s**"
      ],
      "metadata": {
        "id": "WBjow-EZ2P_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Numpy Loading\n",
        "all_eegs = np.load('/kaggle/input/hms-bandpass-0-5-25-order-3/eeg_specs.npy',allow_pickle=True).item()"
      ],
      "metadata": {
        "trusted": true,
        "id": "saUcHZFJ2P_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"padding: 25px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#A51C30\"><b><span style='color:#FFFFFF'>3 |</span></b> <b>Train DataLoader</b></div>"
      ],
      "metadata": {
        "id": "d0FliXoA2P_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"num_masks_x\": (1, 3),\n",
        "    \"num_masks_y\": (1,2),\n",
        "    \"mask_y_length\": (5,10),\n",
        "    \"mask_x_length\": (10, 20),\n",
        "    \"fill_value\": (0,1,2,3,4,5,6,7),\n",
        "}"
      ],
      "metadata": {
        "id": "cnA2c1qd2P_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as albu\n",
        "import cv2\n",
        "TARS = {'Seizure':0, 'LPD':1, 'GPD':2, 'LRDA':3, 'GRDA':4, 'Other':5}\n",
        "TARS2 = {x:y for y,x in TARS.items()}\n",
        "\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, data, batch_size=32, shuffle=False, augment1=False, augment2=False, augment3=False, mode='train',\n",
        "                 specs = spectrograms, eeg_specs = all_eegs):\n",
        "\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.augment1 = augment1\n",
        "        self.augment2= augment2\n",
        "        self.augment3 = augment3\n",
        "        self.mode = mode\n",
        "        self.specs = specs\n",
        "        self.eeg_specs = eeg_specs\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        ct = int( np.ceil( len(self.data) / self.batch_size ) )\n",
        "        return ct\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        X, y = self.__data_generation(indexes)\n",
        "        if self.augment1: X = self.__zoom(X)\n",
        "        if self.augment2: X = self.__cutmix(X)\n",
        "        if self.augment3: X = self.__augment_batch(X)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange( len(self.data) )\n",
        "        if self.shuffle: np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, indexes):\n",
        "        'Generates data containing batch_size samples'\n",
        "\n",
        "        X = np.zeros((len(indexes),128,256,8),dtype='float32')\n",
        "        y = np.zeros((len(indexes),6),dtype='float32')\n",
        "        img = np.ones((128,256),dtype='float32')\n",
        "\n",
        "\n",
        "        for j,i in enumerate(indexes):\n",
        "            row = self.data.iloc[i]\n",
        "            if self.mode=='test':\n",
        "                r = 0\n",
        "            else:\n",
        "                r = int( (row['min'] + row['max'])//4 )\n",
        "\n",
        "            for k in range(4):\n",
        "                # EXTRACT 300 ROWS OF SPECTROGRAM\n",
        "                img = self.specs[row.spec_id][r:r+300,k*100:(k+1)*100].T\n",
        "\n",
        "                # LOG TRANSFORM SPECTROGRAM\n",
        "                img = np.clip(img,np.exp(-4),np.exp(8)) # 이상치 제거\n",
        "                img = np.log(img)\n",
        "\n",
        "                # STANDARDIZE -1~1\n",
        "                ep = 1e-6\n",
        "                m = np.nanmean(img.flatten())\n",
        "                s = np.nanstd(img.flatten())\n",
        "                img = (img-m)/(s+ep) # null 값 방지\n",
        "                img = np.nan_to_num(img, nan=0.0) # fillnan\n",
        "\n",
        "                # CROP TO 256 TIME STEPS\n",
        "                X[j,14:-14,:,k] = img[:,22:-22] / 2.0\n",
        "\n",
        "            # EEG SPECTROGRAMS 50S\n",
        "            # 그전에 미리 log transform, standardize -1~1 진행함\n",
        "            img = self.eeg_specs[row.eeg_id]\n",
        "            X[j,:,:,4:] = img\n",
        "\n",
        "            if self.mode!='test':\n",
        "                y[j,] = row[TARGETS]\n",
        "\n",
        "\n",
        "        return X,y\n",
        "\n",
        "    def __cutmix(self, img_batch, cutmix_prob=0.5):\n",
        "        batch_size, height, width, channels = img_batch.shape\n",
        "        # 랜덤하게 인덱스 선택\n",
        "        idx = np.random.permutation(batch_size)\n",
        "        if np.random.rand() < cutmix_prob:  # cutmix_prob 확률로 cutmix을 수행할지 결정\n",
        "            lam = np.random.beta(2, 2)  # Beta 분포를 사용하여 lambda 값을 샘플링\n",
        "            mixed_batch = []\n",
        "            for i in range(batch_size):\n",
        "                j = idx[i]\n",
        "                mixed_img = img_batch[i].copy()\n",
        "               # Choose random position for cropping\n",
        "                crop_x = np.random.randint(0, width)\n",
        "                crop_y = np.random.randint(0, height)\n",
        "                crop_width = int(width * np.sqrt(1 - lam))\n",
        "                crop_height = int(height * np.sqrt(1 - lam))\n",
        "\n",
        "                if crop_x > 178 and crop_x+crop_width < 78:\n",
        "                    continue\n",
        "\n",
        "               # Mix images using CutMix\n",
        "                mixed_img[crop_y:crop_y + crop_height, crop_x:crop_x + crop_width] = img_batch[j, crop_y:crop_y + crop_height, crop_x:crop_x + crop_width]\n",
        "                mixed_batch.append(mixed_img)\n",
        "            mixed_batch = np.array(mixed_batch)\n",
        "            return mixed_batch\n",
        "        else:\n",
        "            return img_batch\n",
        "\n",
        "    def __random_transform(self, img):\n",
        "        composition = albu.Compose([\n",
        "            albu.XYMasking(**params, p=0.5)\n",
        "        ])\n",
        "        return composition(image=img)['image']\n",
        "\n",
        "    def __augment_batch(self, img_batch):\n",
        "        for i in range(img_batch.shape[0]):\n",
        "            img_batch[i, ] = self.__random_transform(img_batch[i, ])\n",
        "        return img_batch\n",
        "\n",
        "    def __random_scale(self, img):\n",
        "        composition = albu.Compose([\n",
        "            albu.RandomScale(scale_limit=(1.25, 2.0), p=0.5),  # 이미지를 1.1배에서 1.5배 사이로 확대\n",
        "\n",
        "        ])\n",
        "        return composition(image=img)['image']\n",
        "\n",
        "    def __zoom(self, img_batch):\n",
        "        for i in range(img_batch.shape[0]):\n",
        "            img_batch[i, ] = self.__random_scale(img_batch[i, ])\n",
        "        return img_batch"
      ],
      "metadata": {
        "id": "c-ReDGZJ2P_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"padding: 25px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#A51C30\"><b><span style='color:#FFFFFF'>4 |</span></b> <b>Build EfficientNet</b></div>"
      ],
      "metadata": {
        "id": "XFAMoa0i2P_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#A51C30'> 4.1 </span> Train Scheduler </b>\n",
        "- Cosine Trainig Schedule: 연속형으로 LR 값이 작아진다.\n",
        "\n",
        "- Step Training Schedule: 계단식으로 LR 값이 작아진다."
      ],
      "metadata": {
        "id": "Vfl1j3VA2P_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cosine Training Scheduler\n",
        "\n",
        "\n",
        "# Step Training Scheduler\n",
        "def lrfn(epoch):\n",
        "    return [1e-3, 1e-4, 1e-5, 1e-5][epoch]\n",
        "\n",
        "EPOCHS=4\n",
        "LR = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "JN8O2aOL2P_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#A51C30'> 4.2 </span> Install EfficientNet</b>"
      ],
      "metadata": {
        "id": "db9SNhwb2P_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-index --find-links=/kaggle/input/tf-efficientnet-whl-files /kaggle/input/tf-efficientnet-whl-files/efficientnet-1.1.1-py3-none-any.whl"
      ],
      "metadata": {
        "trusted": true,
        "id": "MIAyZ4Yu2P_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#A51C30'> 4.3 </span> Build EfficientNet</b>"
      ],
      "metadata": {
        "id": "3tEJu7Lh2P_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EfficientNetB0**"
      ],
      "metadata": {
        "id": "XhA7V5wb2P_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import efficientnet.tfkeras as efn\n",
        "\n",
        "# 전체구조 설명\n",
        "# input -> kaggle&eeg 별 Concatenate -> Dense -> Softmax\n",
        "def build_model():\n",
        "\n",
        "    # Input(비어 있음)\n",
        "    inp = tf.keras.Input(shape=(128,256,8))\n",
        "    # BackBone\n",
        "    base_model = efn.EfficientNetB0(include_top=False, weights=None, input_shape=None)\n",
        "    base_model.load_weights('/kaggle/input/tf-efficientnet-noisy-student-weights/efficientnet-b0_noisy-student_notop.h5')\n",
        "    # Freezing Backbone Weight\n",
        "    freeze_layers = 40\n",
        "    for layer in base_model.layers[:freeze_layers]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Kaggle Spectrogram\n",
        "    # 128 x 4 = 512, shape: 512 x 256\n",
        "    x1 = [inp[:,:,:,k:k+1] for k in range(4)]\n",
        "    x1 = tf.keras.layers.Concatenate(axis=1)(x1)\n",
        "    # EEG Spectrogram 50s\n",
        "    # 128 X 4 = 512, shape: 512 X 256\n",
        "    x2 = [inp[:,:,:,k+4:k+5] for k in range(4)]\n",
        "    x2 = tf.keras.layers.Concatenate(axis=1)(x2)\n",
        "\n",
        "    x = tf.keras.layers.Concatenate(axis=2)([x1,x2])\n",
        "    x = tf.keras.layers.Concatenate(axis=3)([x,x,x])\n",
        "\n",
        "    # Output\n",
        "    x = base_model(x)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dense(6, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    # Compile(loss: KL, optimizer: Adam)\n",
        "    model = tf.keras.Model(inputs=inp, outputs=x)\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
        "    loss = tf.keras.losses.KLDivergence()\n",
        "    model.compile(loss=loss, optimizer=opt)\n",
        "\n",
        "    return model\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "id": "SU3yK5TP2P_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"padding: 25px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#A51C30\"><b><span style='color:#FFFFFF'>5 |</span></b> <b>Train EfficientB0</b></div>"
      ],
      "metadata": {
        "id": "HGjjoSXn2P_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#A51C30'> 5.1 </span> Training Low Quality</b>"
      ],
      "metadata": {
        "id": "w2DCkbtz2P_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**New Labeling(Low Quality)**"
      ],
      "metadata": {
        "id": "8pFmtU7w2P_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/kaggle/input/labelinglow-quality/train.csv')"
      ],
      "metadata": {
        "id": "8YTh_IHK2P_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold, GroupKFold\n",
        "import tensorflow.keras.backend as K, gc\n",
        "\n",
        "all_oof_low = []\n",
        "all_true_low = []\n",
        "\n",
        "low = train['total_evaluators'] < 10 # low quality\n",
        "\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "for i, (train_index, valid_index) in enumerate(gkf.split(train[low], train[low].target, train[low].patient_id)):\n",
        "\n",
        "    print('#'*25)\n",
        "    print(f'### Fold {i+1}')\n",
        "\n",
        "    train_gen = DataGenerator(train[low].iloc[train_index], shuffle=True, batch_size=32, augment2=True) # cutmix\n",
        "    valid_gen = DataGenerator(train[low].iloc[valid_index], shuffle=False, batch_size=64, mode='valid')\n",
        "\n",
        "    print(f'### train size {len(train_index)}, valid size {len(valid_index)}')\n",
        "    print('#'*25)\n",
        "\n",
        "    K.clear_session()\n",
        "    with strategy.scope():\n",
        "        model = build_model()\n",
        "    if LOAD_MODELS_FROM is None:\n",
        "        model.fit(train_gen, verbose=1,\n",
        "              validation_data = valid_gen,\n",
        "              epochs=EPOCHS, callbacks = [LR])\n",
        "        model.save_weights(f'EffNet_v{VER}_f{i}_low.h5')\n",
        "    else:\n",
        "        model.load_weights(f'{LOAD_MODELS_FROM}EffNet_v{VER}_f{i}_low.h5')\n",
        "\n",
        "    oof = model.predict(valid_gen, verbose=1)\n",
        "    all_oof_low.append(oof)\n",
        "    all_true_low.append(train[low].iloc[valid_index][TARGETS].values)\n",
        "\n",
        "    del model, oof, train_gen, valid_gen\n",
        "    gc.collect()\n",
        "\n",
        "all_oof_low = np.concatenate(all_oof_low)\n",
        "all_true_low = np.concatenate(all_true_low)"
      ],
      "metadata": {
        "trusted": true,
        "id": "qugw24fv2P_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#A51C30'> 5.2 </span> First CV</b>"
      ],
      "metadata": {
        "id": "QWwtoAXm2P_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/kaggle/input/kaggle-kl-div')\n",
        "from kaggle_kl_div import score\n",
        "\n",
        "oof = pd.DataFrame(all_oof_low.copy())\n",
        "oof['id'] = np.arange(len(oof))\n",
        "\n",
        "true = pd.DataFrame(all_true_low.copy())\n",
        "true['id'] = np.arange(len(true))\n",
        "\n",
        "cv = score(solution=true, submission=oof, row_id_column_name='id')\n",
        "print('CV Score KL-Div for EfficientNetB0 with low =',cv)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Kqa68LBS2P_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#A51C30'> 5.4 </span> Second Training</b>"
      ],
      "metadata": {
        "id": "nEWJXODb2P_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LOAD_MODELS_FROM = None"
      ],
      "metadata": {
        "id": "u69PDtcp2P_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold, GroupKFold\n",
        "import tensorflow.keras.backend as K, gc\n",
        "\n",
        "all_oof_high = []\n",
        "all_true_high = []\n",
        "\n",
        "high = train['total_evaluators'] >= 4 # high quality\n",
        "\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "for i, (train_index, valid_index) in enumerate(gkf.split(train[high], train[high].target, train[high].patient_id)):\n",
        "\n",
        "    print('#'*25)\n",
        "    print(f'### Fold {i+1}')\n",
        "\n",
        "    train_gen = DataGenerator(train[high].iloc[train_index], shuffle=True, batch_size=32, augment1=False)\n",
        "    valid_gen = DataGenerator(train[high].iloc[valid_index], shuffle=False, batch_size=64, mode='valid')\n",
        "\n",
        "    print(f'### train size {len(train_index)}, valid size {len(valid_index)}')\n",
        "    print('#'*25)\n",
        "\n",
        "    K.clear_session()\n",
        "    with strategy.scope():\n",
        "        model = build_model()\n",
        "    if LOAD_MODELS_FROM is None:\n",
        "        model.load_weights(f'/kaggle/input/low-quality/EffNet_v{VER}_f{i}_low.h5')\n",
        "        model.fit(train_gen, verbose=1,\n",
        "              validation_data = valid_gen,\n",
        "              epochs=EPOCHS, callbacks = [LR])\n",
        "        model.save_weights(f'EffNet_v{VER}_f{i}.h5')\n",
        "    else:\n",
        "        model.load_weights(f'{LOAD_MODELS_FROM}EffNet_v{VER}_f{i}.h5')\n",
        "\n",
        "    oof = model.predict(valid_gen, verbose=1)\n",
        "    all_oof_high.append(oof)\n",
        "    all_true_high.append(train[high].iloc[valid_index][TARGETS].values)\n",
        "\n",
        "    del model, oof\n",
        "    gc.collect()\n",
        "\n",
        "all_oof_high = np.concatenate(all_oof_high)\n",
        "all_true_high = np.concatenate(all_true_high)"
      ],
      "metadata": {
        "trusted": true,
        "id": "K3NQfeNu2P_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#A51C30'> 5.5 </span> Second CV</b>"
      ],
      "metadata": {
        "id": "z1CT8xHd2P_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oof = pd.DataFrame(all_oof_high.copy())\n",
        "oof['id'] = np.arange(len(oof))\n",
        "\n",
        "true = pd.DataFrame(all_true_high.copy())\n",
        "true['id'] = np.arange(len(true))\n",
        "\n",
        "cv = score(solution=true, submission=oof, row_id_column_name='id')\n",
        "print('CV Score KL-Div for two_stage_EfficientNetB0 =',cv)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Ujfe4i8k2P_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del all_eegs, spectrograms; gc.collect()\n",
        "test = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/test.csv')\n",
        "print('Test shape',test.shape)\n",
        "test.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "se8KIAlz2P_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# READ ALL SPECTROGRAMS\n",
        "PATH2 = '/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/'\n",
        "files2 = os.listdir(PATH2)\n",
        "print(f'There are {len(files2)} test spectrogram parquets')\n",
        "\n",
        "spectrograms2 = {}\n",
        "for i,f in enumerate(files2):\n",
        "    if i%100==0: print(i,', ',end='')\n",
        "    tmp = pd.read_parquet(f'{PATH2}{f}')\n",
        "    name = int(f.split('.')[0])\n",
        "    spectrograms2[name] = tmp.iloc[:,1:].values\n",
        "\n",
        "# RENAME FOR DATALOADER\n",
        "test = test.rename({'spectrogram_id':'spec_id'},axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "0UlqhW422P_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# READ ALL EEG SPECTROGRAMS\n",
        "PATH2 = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/'\n",
        "DISPLAY = 1\n",
        "EEG_IDS2 = test.eeg_id.unique()\n",
        "all_eegs2 = {}\n",
        "\n",
        "print('Converting Test EEG to Spectrograms...'); print()\n",
        "for i,eeg_id in enumerate(EEG_IDS2):\n",
        "\n",
        "    # CREATE SPECTROGRAM FROM EEG PARQUET\n",
        "    img = spectrogram_from_eeg(f'{PATH2}{eeg_id}.parquet', i<DISPLAY)\n",
        "    all_eegs2[eeg_id] = img"
      ],
      "metadata": {
        "trusted": true,
        "id": "CppVT2aQ2P_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "model = build_model()\n",
        "\n",
        "# TTA: Test Time Argument\n",
        "test_gen = DataGenerator(test, shuffle=False, batch_size=64, mode='test', augment3=False,\n",
        "                         specs = spectrograms2, eeg_specs = all_eegs2) # HFlip\n",
        "\n",
        "for i in range(5):\n",
        "    print(f'Fold {i+1}')\n",
        "    if LOAD_MODELS_FROM:\n",
        "        model.load_weights(f'{LOAD_MODELS_FROM}EffNet_v{VER}_f{i}.h5')\n",
        "    else:\n",
        "        model.load_weights(f'EffNet_v{VER}_f{i}.h5')\n",
        "    pred = model.predict(test_gen, verbose=1)\n",
        "    preds.append(pred)\n",
        "\n",
        "\n",
        "pred = np.mean(preds,axis=0)\n",
        "print()\n",
        "print('Test preds shape',pred.shape)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Nc6PZqCf2P_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub = pd.DataFrame({'eeg_id':test.eeg_id.values})\n",
        "sub[TARGETS] = pred\n",
        "sub.to_csv('submission.csv',index=False)\n",
        "print('Submissionn shape',sub.shape)\n",
        "sub.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "6e-50zUo2P_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub.iloc[:,-6:].sum(axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "S2IMZIQE2P_z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}